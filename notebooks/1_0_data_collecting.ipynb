{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsHF2gX4ddx8"
      },
      "source": [
        "# Tổng quan phần thu thập dữ liệu\n",
        "1. Mục tiêu\n",
        "- Hiện nay có rất nhiều nhà tuyển dụng đăng thông tin tuyển dụng trên nhiều trang web như : https://vieclam24h.vn/, https://www.topcv.vn/viec-lam, https://careerbuilder.vn/tim-viec-lam.html, https://www.vieclamtot.com/viec-lam\n",
        "- Do đó để dự đoán xu hướng công việc cũng như tìm hiểu thị trường việc làm, chúng ta sẽ chọn thu thập dữ liệu từ các trang web [Viêc làm 24h](https://vieclam24h.vn/).\n",
        "2. Công cụ sử dụng\n",
        "- Trong phần này, ta sử dụng những thư viện được python hỗ trợ như: request_html để gửi yêu cầu lấy trang web về.\n",
        "- BeautifulSoup để phân tích cấu trúc của trang web. Sau đó lấy những trường cần thiết.\n",
        "3. Các bước thu thập dữ liệu\n",
        "- Ban đầu trang chủ trang web có một các thông tin về các công việc mới nhất, các công việc được đăng gần đây nhất. Ta sẽ lấy các link của các công việc này. Sau đó đến đường dẫn các công việc này để lấy thông tin chi tiết về công việc. Chúng em sẽ có 2 bước thu thập dữ liệu:\n",
        "    - Step 1: Thu thập dữ liệu từ trang chủ sau đó lưu các đường link vào 'job_pool.csv'\n",
        "    - Thu thập dữ liệu từ các trang chi tiết và lưu tất cả công việc vào một dataset có tên là 'raw_dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBvlm4Y9sicN",
        "outputId": "d1a68318-40e6-4f9f-870d-71615d2c6738"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "An8aohfvsm0Z"
      },
      "outputs": [],
      "source": [
        "from os import path\n",
        "class Path():\n",
        "  def __init__(self) -> None:\n",
        "      job_pool_path = 'job_pool.csv'\n",
        "      raw_dataset_path = 'raw_dataset.csv'\n",
        "\n",
        "path = Path()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "731vHlsHscuG"
      },
      "outputs": [],
      "source": [
        "# !pip install requests-html --quiet\n",
        "# !pip install bs4 --quiet\n",
        "# !pip install --upgrade lxml_html_clean --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5edptqZ3ddyA"
      },
      "outputs": [],
      "source": [
        "# import những  thư viện cần thiết\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from requests_html import HTML\n",
        "from requests.exceptions import RequestException\n",
        "from requests_html import HTMLSession\n",
        "from bs4 import BeautifulSoup\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG8hSnwJddyC"
      },
      "outputs": [],
      "source": [
        "def get_content(url, headers, max_attempts=5):\n",
        "    session = HTMLSession()\n",
        "    for attempt in range(max_attempts):\n",
        "        try:\n",
        "            response = session.get(url, headers=headers)\n",
        "            if response.status_code == 200:\n",
        "                return response\n",
        "            else:\n",
        "                print(f'Attempt {attempt+1} failed with status: {response.status_code}')\n",
        "                \n",
        "        except RequestException as e:\n",
        "            print(f'Attempt {attempt+1} failed due to: {str(e)}')\n",
        "            \n",
        "        time.sleep(10)\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnE9Eu4BddyD"
      },
      "outputs": [],
      "source": [
        "BASE_URL = 'https://vieclam24h.vn'\n",
        "\n",
        "headers = {\n",
        "   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0U87wI8scuR"
      },
      "outputs": [],
      "source": [
        "# url = 'https://vieclam24h.vn/tim-kiem-viec-lam-nhanh?degree_requirement[]={}&experience_range={}&occupation_ids[]={}&working_method[]={}'\n",
        "url = 'https://vieclam24h.vn/tim-kiem-viec-lam-nhanh?occupation_ids[]={}&working_method[]={}'\n",
        "# degree_requirements = 8\n",
        "# experience_range = 8\n",
        "occupation_ids = 53\n",
        "working_methods = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5K8PHn-scuT"
      },
      "source": [
        "## Step 0: Mô phỏng trên 1 test case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "JnpS2CuHscuV",
        "outputId": "4c32abb5-df66-42d8-e6a6-6e9e9aea8e0c"
      },
      "outputs": [],
      "source": [
        "jobs_list = []\n",
        "# test\n",
        "new_url = 'https://vieclam24h.vn/tim-kiem-viec-lam-nhanh?degree_requirement[]=1&experience_range=3&occupation_ids[]=1&working_method[]=1'\n",
        "page_content = get_content(new_url, headers)\n",
        "# Lưu page content vào file\n",
        "# with open('page_content.html', 'w') as f:\n",
        "#     f.write(page_content.text)\n",
        "\n",
        "# Lấy số lượng việc làm\n",
        "try:\n",
        "    soup = BeautifulSoup(page_content.text, 'html.parser')\n",
        "    buffer1 = soup.find('div', class_='relative lg:text-2xl text-xl box-border lg:leading-10 mb-4 m-auto lg:w-full w-[100%] px-0')\n",
        "    strong_tag = buffer1.find('strong')\n",
        "    total_jobs = int(strong_tag.text)\n",
        "except:\n",
        "    total_jobs = 0\n",
        "\n",
        "\n",
        "print('Total jobs:', total_jobs)\n",
        "\n",
        "n_pages = min(51, math.ceil(total_jobs/30) + 1)\n",
        "\n",
        "\n",
        "# for page in range(1, n_pages + 1):\n",
        "for page in range(1, 2):\n",
        "    page_url = new_url + f'&page={page}'\n",
        "\n",
        "\n",
        "    page_content = get_content(page_url, headers)\n",
        "    try:\n",
        "        soup = BeautifulSoup(page_content.text, 'html.parser')\n",
        "\n",
        "        containers = soup.find_all('div', class_='relative lg:h-[115px] w-full flex rounded-sm lg:mb-3 mb-2 lg:hover:shadow-md')\n",
        "    except:\n",
        "        containers = []\n",
        "    for container in containers:\n",
        "        dict_job = {}\n",
        "\n",
        "        buffer = BASE_URL + container.find('a', href=True)['href']\n",
        "        dict_job['Liên kết'] = buffer if buffer else None\n",
        "\n",
        "        buffer = container.find('div', class_='relative lg:w-full w-11/12 flex items-start flex-1 overflow-hidden pr-2 lg:pr-8')\n",
        "        dict_job['Tên công việc'] = buffer.text if buffer else None\n",
        "\n",
        "\n",
        "        buffer = container.find('span', class_='text-se-neutral-80 text-14 whitespace-nowrap font-medium')\n",
        "        dict_job['Mức lương'] = buffer.text if buffer else None\n",
        "\n",
        "        buffer = container.find('span', class_='text-se-neutral-80 whitespace-nowrap text-14')\n",
        "        dict_job['Khu vực tuyển'] = buffer.text if buffer else None\n",
        "\n",
        "        jobs_list.append(dict_job)\n",
        "job_pd = pd.DataFrame(jobs_list)\n",
        "job_pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZXUe1y0scuZ",
        "outputId": "58270fe3-72fd-40b5-e113-dfd400563d72"
      },
      "outputs": [],
      "source": [
        "job_deatail_list = []\n",
        "for i, job_url in enumerate(job_pd['Liên kết'].head(5)):\n",
        "\n",
        "\n",
        "    job_content = get_content(job_url, headers=headers)\n",
        "    if (job_content != None):\n",
        "        soup = BeautifulSoup(job_content.text, 'html.parser')\n",
        "\n",
        "    # # Lưu page content vào file\n",
        "    # with open('job_content.html', 'w') as f:\n",
        "    #     f.write(job_content.text)\n",
        "\n",
        "    dict_job = {}\n",
        "\n",
        "    dict_job['Liên kết'] = job_url\n",
        "\n",
        "    overview = soup.find('div', class_='md:ml-7 w-full')\n",
        "    try:\n",
        "        buffer = overview.find('h2', class_='font-normal text-16 text-se-neutral-64 mb-4')\n",
        "        dict_job['Tên công ty'] = buffer.text if buffer else None\n",
        "    except:\n",
        "        dict_job['Tên công ty'] = None\n",
        "    try:\n",
        "        buffer = overview.find('h1', class_='font-semibold text-18 md:text-24 leading-snug')\n",
        "        dict_job['Tên công việc'] = buffer.text if buffer else None\n",
        "    except:\n",
        "        dict_job['Tên công việc'] = None\n",
        "\n",
        "    date_view = overview.find_all('span', class_='font-medium pr-1')\n",
        "    try:\n",
        "        dict_job['Ngày cập nhật'] = date_view[0].find_next_sibling('span').text if date_view[0] else None\n",
        "    except:\n",
        "        dict_job['Ngày cập nhật'] = None\n",
        "\n",
        "    try:\n",
        "        dict_job['Lượt xem'] = date_view[1].find_next_sibling('span').text if date_view[1] else None\n",
        "    except:\n",
        "        dict_job['Lượt xem'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = overview.find('p', class_='font-semibold text-14 text-[#8B5CF6]')\n",
        "        dict_job['Mức lương'] = buffer.text if buffer else None\n",
        "    except:\n",
        "        dict_job['Mức lương'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = overview.find_all('a', class_ =\"hover:text-se-accent\")\n",
        "        dict_job['Khu vực tuyển'] = ' '.join([element.text for element in buffer]) if buffer else None\n",
        "    except:\n",
        "        dict_job['Khu vực tuyển'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Yêu cầu giới tính\")\n",
        "        dict_job['Yêu cầu giới tính'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Yêu cầu giới tính'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Cấp bậc\")\n",
        "        dict_job['Cấp bậc'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Cấp bậc'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Thời gian thử việc\")\n",
        "        dict_job['Thời gian thử việc'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Thời gian thử việc'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Số lượng tuyển\")\n",
        "        dict_job['Số lượng tuyển'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Số lượng tuyển'] = None\n",
        "\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Hình thức làm việc\")\n",
        "        dict_job['Hình thức làm việc'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Hình thức làm việc'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Độ tuổi\")\n",
        "        dict_job['Độ tuổi'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Độ tuổi'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Yêu cầu bằng cấp\")\n",
        "        dict_job['Yêu cầu bằng cấp'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Yêu cầu bằng cấp'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Yêu cầu kinh nghiệm\")\n",
        "        dict_job['Yêu cầu kinh nghiệm'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Yêu cầu kinh nghiệm'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Ngành nghề\")\n",
        "        dict_job['Ngành nghề'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Ngành nghề'] = None\n",
        "\n",
        "\n",
        "    try:\n",
        "        buffer1 = soup.find('div', string=\"Từ khoá\")\n",
        "        buffer2 = buffer1.find_next_sibling('div')\n",
        "        keywords = [a.text for a in buffer2.find_all('a')] if buffer2 else None\n",
        "        dict_job['Từ khóa'] = '; '.join(keywords) if keywords else None\n",
        "    except:\n",
        "        dict_job['Từ khóa'] = None\n",
        "\n",
        "    company = soup.find('div', class_='px-4 md:px-10 py-4 bg-white shadow-sd-12 rounded-sm mt-4 lg:mb-6')\n",
        "\n",
        "    buffers = company.find_all('div', class_= 'text-14 text-se-neutral-64 w-full max-w-[125px] mr-2')\n",
        "    try:\n",
        "        for buffer in buffers:\n",
        "            if buffer.get_text() == 'Địa chỉ:':\n",
        "                dict_job['Địa chỉ công ty'] = buffer.find_next_sibling('div').text if buffer else None\n",
        "            if buffer.get_text() == 'Quy mô:':\n",
        "                dict_job['Quy mô công ty'] = buffer.find_next_sibling('div').text if buffer else None\n",
        "    except:\n",
        "        dict_job['Địa chỉ công ty'] = None\n",
        "        dict_job['Quy mô công ty'] = None\n",
        "\n",
        "    job_deatail_list.append(dict_job)\n",
        "\n",
        "raw_job_details = pd.DataFrame(job_deatail_list)\n",
        "raw_job_details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrBBSf6tddyD"
      },
      "source": [
        "\n",
        "## Step 1: Lấy những liên kết của trang web công việc\n",
        "- Đầu tiên, khi vô một trang web tìm việc, ta sẽ thấy một loạt danh sách các công việc, sau khi nhấn vào từng cái sẽ liên kết trực tiếp đến trang chi tiết công việc. Vậy đầu tiên ta đến trang tìm kiếm và lọc tất cả các đường dẫn đến công việc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZHfjaPKscue",
        "outputId": "f938fc0b-b865-44a7-ee79-674d236a5485"
      },
      "outputs": [],
      "source": [
        "jobs_list = []\n",
        "\n",
        "for occupation_id in range(1, occupation_ids + 1):\n",
        "    for working_method in range(1, working_methods + 1):\n",
        "\n",
        "        new_url = url.format(occupation_id, working_method)\n",
        "        print(new_url)\n",
        "\n",
        "        page_content = get_content(new_url, headers)\n",
        "\n",
        "        try:\n",
        "            soup = BeautifulSoup(page_content.text, 'html.parser')\n",
        "            buffer1 = soup.find('div', class_='relative lg:text-2xl text-xl box-border lg:leading-10 mb-4 m-auto lg:w-full w-[100%] px-0')\n",
        "            strong_tag = buffer1.find('strong')\n",
        "            total_jobs = int(strong_tag.text)\n",
        "        except:\n",
        "            total_jobs = 0\n",
        "\n",
        "\n",
        "        print('Total jobs:', total_jobs)\n",
        "\n",
        "        n_pages = min(51, math.ceil(total_jobs/30) + 1)\n",
        "\n",
        "\n",
        "        for page in range(1, n_pages + 1):\n",
        "        # for page in range(1, 2):\n",
        "            page_url = new_url + f'&page={page}'\n",
        "\n",
        "\n",
        "            page_content = get_content(page_url, headers)\n",
        "            try:\n",
        "                soup = BeautifulSoup(page_content.text, 'html.parser')\n",
        "\n",
        "                containers = soup.find_all('div', class_='relative lg:h-[115px] w-full flex rounded-sm lg:mb-3 mb-2 lg:hover:shadow-md')\n",
        "            except:\n",
        "                containers = []\n",
        "            for container in containers:\n",
        "                dict_job = {}\n",
        "\n",
        "                buffer = BASE_URL + container.find('a', href=True)['href']\n",
        "                dict_job['Liên kết'] = buffer if buffer else None\n",
        "\n",
        "                buffer = container.find('div', class_='relative lg:w-full w-11/12 flex items-start flex-1 overflow-hidden pr-2 lg:pr-8')\n",
        "                dict_job['Tên công việc'] = buffer.text if buffer else None\n",
        "\n",
        "\n",
        "                buffer = container.find('span', class_='text-se-neutral-80 text-14 whitespace-nowrap font-medium')\n",
        "                dict_job['Mức lương'] = buffer.text if buffer else None\n",
        "\n",
        "                buffer = container.find('span', class_='text-se-neutral-80 whitespace-nowrap text-14')\n",
        "                dict_job['Khu vực tuyển'] = buffer.text if buffer else None\n",
        "\n",
        "                jobs_list.append(dict_job)\n",
        "    time.sleep(5)\n",
        "job_pool = pd.DataFrame(jobs_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGdc9TA_scug"
      },
      "outputs": [],
      "source": [
        "# Xóa trung lặp\n",
        "job_pool = job_pool.drop_duplicates(subset=['Liên kết'])\n",
        "job_pool.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54VTapq4ddyG"
      },
      "outputs": [],
      "source": [
        "# Lưu dữ liệu vào file csv\n",
        "job_pool.drop_duplicates(inplace=True)\n",
        "job_pool.to_csv(path.job_pool_path, index=False, encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqGQtqaJddyG"
      },
      "source": [
        "# Step 2: Thu thập dữ liệu của từng trang web\n",
        "- Sau khi thu thập được các link trang web, ta tiến hành thu thập dữ liệu của từng trang web bằng cách sử dụng cách tương tự"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6qAmD1BddyH"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path.job_pool_path)\n",
        "# df = job_pd.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn6gDpi8ddyH",
        "outputId": "b5f200fb-06f1-4f11-9652-f8823e5e1a33"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJWsPs5CddyH",
        "outputId": "0e60ea98-98a1-4142-88db-cf18d74e5940"
      },
      "outputs": [],
      "source": [
        "\n",
        "job_deatail_list = []\n",
        "for i, job_url in enumerate(df['Liên kết']):\n",
        "\n",
        "    print(f'Processing {i+1}/{len(df)}: {url}')\n",
        "\n",
        "    job_content = get_content(job_url, headers=headers)\n",
        "    if (job_content != None):\n",
        "        soup = BeautifulSoup(job_content.text, 'html.parser')\n",
        "\n",
        "    # Lưu page content vào file\n",
        "    with open('job_content.html', 'w') as f:\n",
        "        f.write(job_content.text)\n",
        "\n",
        "    dict_job = {}\n",
        "\n",
        "    dict_job['Liên kết'] = job_url\n",
        "\n",
        "    overview = soup.find('div', class_='md:ml-7 w-full')\n",
        "    try:\n",
        "        buffer = overview.find('h2', class_='font-normal text-16 text-se-neutral-64 mb-4')\n",
        "        dict_job['Tên công ty'] = buffer.text if buffer else None\n",
        "    except:\n",
        "        dict_job['Tên công ty'] = None\n",
        "    try:\n",
        "        buffer = overview.find('h1', class_='font-semibold text-18 md:text-24 leading-snug')\n",
        "        dict_job['Tên công việc'] = buffer.text if buffer else None\n",
        "    except:\n",
        "        dict_job['Tên công việc'] = None\n",
        "\n",
        "    date_view = overview.find_all('span', class_='font-medium pr-1')\n",
        "    try:\n",
        "        dict_job['Ngày cập nhật'] = date_view[0].find_next_sibling('span').text if date_view[0] else None\n",
        "    except:\n",
        "        dict_job['Ngày cập nhật'] = None\n",
        "\n",
        "    try:\n",
        "        dict_job['Lượt xem'] = date_view[1].find_next_sibling('span').text if date_view[1] else None\n",
        "    except:\n",
        "        dict_job['Lượt xem'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = overview.find('p', class_='font-semibold text-14 text-[#8B5CF6]')\n",
        "        dict_job['Mức lương'] = buffer.text if buffer else None\n",
        "    except:\n",
        "        dict_job['Mức lương'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = overview.find_all('a', class_ =\"hover:text-se-accent\")\n",
        "        dict_job['Khu vực tuyển'] = ' '.join([element.text for element in buffer]) if buffer else None\n",
        "    except:\n",
        "        dict_job['Khu vực tuyển'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Yêu cầu giới tính\")\n",
        "        dict_job['Yêu cầu giới tính'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Yêu cầu giới tính'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Cấp bậc\")\n",
        "        dict_job['Cấp bậc'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Cấp bậc'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Thời gian thử việc\")\n",
        "        dict_job['Thời gian thử việc'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Thời gian thử việc'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Số lượng tuyển\")\n",
        "        dict_job['Số lượng tuyển'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Số lượng tuyển'] = None\n",
        "\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Hình thức làm việc\")\n",
        "        dict_job['Hình thức làm việc'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Hình thức làm việc'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Độ tuổi\")\n",
        "        dict_job['Độ tuổi'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Độ tuổi'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Yêu cầu bằng cấp\")\n",
        "        dict_job['Yêu cầu bằng cấp'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Yêu cầu bằng cấp'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Yêu cầu kinh nghiệm\")\n",
        "        dict_job['Yêu cầu kinh nghiệm'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Yêu cầu kinh nghiệm'] = None\n",
        "\n",
        "    try:\n",
        "        buffer = soup.find('p', string=\"Ngành nghề\")\n",
        "        dict_job['Ngành nghề'] = buffer.find_next_sibling('p').get_text() if buffer else None\n",
        "    except:\n",
        "        dict_job['Ngành nghề'] = None\n",
        "\n",
        "\n",
        "    try:\n",
        "        buffer1 = soup.find('div', string=\"Từ khoá\")\n",
        "        buffer2 = buffer1.find_next_sibling('div')\n",
        "        keywords = [a.text for a in buffer2.find_all('a')] if buffer2 else None\n",
        "        dict_job['Từ khóa'] = '; '.join(keywords) if keywords else None\n",
        "    except:\n",
        "        dict_job['Từ khóa'] = None\n",
        "\n",
        "    company = soup.find('div', class_='px-4 md:px-10 py-4 bg-white shadow-sd-12 rounded-sm mt-4 lg:mb-6')\n",
        "\n",
        "    buffers = company.find_all('div', class_= 'text-14 text-se-neutral-64 w-full max-w-[125px] mr-2')\n",
        "    try:\n",
        "        for buffer in buffers:\n",
        "            if buffer.get_text() == 'Địa chỉ:':\n",
        "                dict_job['Địa chỉ công ty'] = buffer.find_next_sibling('div').text if buffer else None\n",
        "            if buffer.get_text() == 'Quy mô:':\n",
        "                dict_job['Quy mô công ty'] = buffer.find_next_sibling('div').text if buffer else None\n",
        "    except:\n",
        "        dict_job['Địa chỉ công ty'] = None\n",
        "        dict_job['Quy mô công ty'] = None\n",
        "\n",
        "    job_deatail_list.append(dict_job)\n",
        "\n",
        "raw_job_details = pd.DataFrame(job_deatail_list)\n",
        "raw_job_details.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc3Bx6fFddyI",
        "outputId": "7c46f144-8925-4c98-cdd5-d52bdd3d2e98"
      },
      "outputs": [],
      "source": [
        "# Lưu vào file craw_dataset.csv\n",
        "raw_job_details.info()\n",
        "raw_job_details.to_csv(path.raw_job_details_path, index=False, encoding='utf-8-sig')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
